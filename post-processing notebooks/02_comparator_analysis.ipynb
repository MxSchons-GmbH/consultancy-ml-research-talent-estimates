{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparator Analysis: ML vs Non-ML Organizations\n",
    "\n",
    "This notebook generates outputs for the comparator datasets:\n",
    "- **ML Comparators**: Established ML organizations (positive controls)\n",
    "- **Non-ML Comparators**: Non-ML organizations (negative controls)\n",
    "\n",
    "For each comparator group, we generate:\n",
    "1. Company table (CSV)\n",
    "2. ML estimates plot (PNG)\n",
    "3. ML landscape plot (PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle, Patch\n",
    "import matplotlib.ticker as mticker\n",
    "import warnings\n",
    "import re\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.patches import FancyBboxPatch\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# =============================================================================\n",
    "# DESIGN SYSTEM \u2014 Academic/Scientific Style\n",
    "# =============================================================================\n",
    "\n",
    "FONT_FAMILY = 'Helvetica Neue'\n",
    "FONT_SIZES = {\n",
    "    'title': 14,\n",
    "    'subtitle': 11,\n",
    "    'axis_label': 11,\n",
    "    'tick_label': 9,\n",
    "    'legend': 9,\n",
    "    'annotation': 8,\n",
    "    'org_label': 7,\n",
    "}\n",
    "\n",
    "plt.rcParams.update({\n",
    "    'font.family': 'sans-serif',\n",
    "    'font.sans-serif': ['Helvetica Neue', 'Helvetica', 'Arial', 'DejaVu Sans'],\n",
    "    'font.size': FONT_SIZES['tick_label'],\n",
    "    'axes.titlesize': FONT_SIZES['title'],\n",
    "    'axes.labelsize': FONT_SIZES['axis_label'],\n",
    "    'xtick.labelsize': FONT_SIZES['tick_label'],\n",
    "    'ytick.labelsize': FONT_SIZES['tick_label'],\n",
    "    'legend.fontsize': FONT_SIZES['legend'],\n",
    "    'figure.titlesize': FONT_SIZES['title'],\n",
    "    'axes.titleweight': 'medium',\n",
    "    'axes.labelweight': 'regular',\n",
    "    'axes.linewidth': 0.8,\n",
    "    'axes.spines.top': False,\n",
    "    'axes.spines.right': False,\n",
    "    'axes.grid': True,\n",
    "    'grid.alpha': 0.25,\n",
    "    'grid.linewidth': 0.5,\n",
    "    'grid.linestyle': '-',\n",
    "    'figure.facecolor': 'white',\n",
    "    'axes.facecolor': 'white',\n",
    "    'savefig.facecolor': 'white',\n",
    "    'savefig.dpi': 300,\n",
    "})\n",
    "\n",
    "# =============================================================================\n",
    "# COLOR PALETTE\n",
    "# =============================================================================\n",
    "\n",
    "PALETTE = {\n",
    "    'blue':     '#3C5488',\n",
    "    'red':      '#DC3220',\n",
    "    'green':    '#009988',\n",
    "    'gold':     '#E68613',\n",
    "    'purple':   '#7B4B94',\n",
    "    'gray':     '#868686',\n",
    "}\n",
    "\n",
    "COLORS = {\n",
    "    'ci_pure_probit': '#2C6E49',\n",
    "    'ci_adjusted_synthetic': '#7B4B94',\n",
    "    'probable':     '#2C6E49',\n",
    "    'possible':     '#E68613',\n",
    "    'nonzero':      '#7EB5D6',\n",
    "    'not_detected': '#868686',\n",
    "    'primary':    '#3C5488',\n",
    "    'secondary':  '#009988',\n",
    "    'muted':      '#868686',\n",
    "    'background': '#F5F5F5',\n",
    "    'gridline':   '#E0E0E0',\n",
    "}\n",
    "\n",
    "LANDSCAPE_PALETTE = {\n",
    "    \"Probable\":     COLORS['probable'],\n",
    "    \"Possible\":     COLORS['possible'],\n",
    "    \"Non-zero\":     COLORS['nonzero'],\n",
    "    \"Not Detected\": COLORS['not_detected'],\n",
    "}\n",
    "\n",
    "LANDSCAPE_MARKERS = {\n",
    "    \"Probable\":     \"D\",\n",
    "    \"Possible\":     \"s\",\n",
    "    \"Non-zero\":     \"^\",\n",
    "    \"Not Detected\": \"o\",\n",
    "}\n",
    "\n",
    "ESTIMATOR_STYLES = {\n",
    "    'filter_broad_yes':           {'color': PALETTE['gray'],   'marker': 'o', 'size': 24},\n",
    "    'filter_strict_no':           {'color': PALETTE['gray'],   'marker': 'v', 'size': 24},\n",
    "    'filter_broad_yes_strict_no': {'color': '#5A5A5A',         'marker': 's', 'size': 24},\n",
    "    'claude_total_accepted':      {'color': PALETTE['blue'],   'marker': 'D', 'size': 36},\n",
    "    'gpt5_total_accepted':        {'color': PALETTE['green'],  'marker': '^', 'size': 36},\n",
    "    'gemini_total_accepted':      {'color': PALETTE['gold'],   'marker': 'P', 'size': 40},\n",
    "}\n",
    "\n",
    "ESTIMATOR_LABELS = {\n",
    "    'filter_broad_yes': 'Keyword: Broad Yes',\n",
    "    'filter_strict_no': 'Keyword: Strict No', \n",
    "    'filter_broad_yes_strict_no': 'Keyword: Broad+Strict',\n",
    "    'claude_total_accepted': 'Claude (sonnet-4)',\n",
    "    'gpt5_total_accepted': 'GPT-5-mini',\n",
    "    'gemini_total_accepted': 'Gemini 2.5 Flash',\n",
    "}\n",
    "\n",
    "# =============================================================================\n",
    "# CONFIGURATION\n",
    "# =============================================================================\n",
    "\n",
    "SAVE_OUTPUTS = True\n",
    "DATA_DIR = Path('..')\n",
    "\n",
    "print(f\"Data directory: {DATA_DIR.resolve()}\")\n",
    "print(f\"Output saving: {'enabled' if SAVE_OUTPUTS else 'disabled'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# HELPER FUNCTIONS\n",
    "# =============================================================================\n",
    "\n",
    "def assign_confidence_category(q10, q50, q90):\n",
    "    \"\"\"Assign organization to confidence category based on statistical estimates.\"\"\"\n",
    "    if pd.isna(q10) or pd.isna(q50) or pd.isna(q90):\n",
    "        return \"Not Detected\"\n",
    "    if q10 > 0:\n",
    "        return \"Probable\"\n",
    "    if q50 > 0:\n",
    "        return \"Possible\"\n",
    "    if q90 > 0:\n",
    "        return \"Non-zero\"\n",
    "    return \"Not Detected\"\n",
    "\n",
    "\n",
    "def format_log_axis(ax, axis='y', limits=(1, 10000)):\n",
    "    \"\"\"Format log-scale axis with clean tick labels.\"\"\"\n",
    "    if axis == 'y':\n",
    "        ax.set_yscale('log')\n",
    "        ax.set_ylim(limits)\n",
    "        ticks = [t for t in [1, 10, 100, 1000, 10000] if limits[0] <= t <= limits[1]]\n",
    "        ax.set_yticks(ticks)\n",
    "        ax.set_yticklabels([f'{t:,}' if t >= 1000 else str(t) for t in ticks])\n",
    "        ax.yaxis.set_minor_locator(mticker.NullLocator())\n",
    "    else:\n",
    "        ax.set_xscale('log')\n",
    "        ax.set_xlim(limits)\n",
    "        ticks = [t for t in [1, 10, 100, 1000, 10000] if limits[0] <= t <= limits[1]]\n",
    "        ax.set_xticks(ticks)\n",
    "        ax.set_xticklabels([f'{t:,}' if t >= 1000 else str(t) for t in ticks])\n",
    "        ax.xaxis.set_minor_locator(mticker.NullLocator())\n",
    "\n",
    "\n",
    "def format_int_iso(n):\n",
    "    \"\"\"Format integers with spaces between groups of three digits.\"\"\"\n",
    "    if n is None or (isinstance(n, float) and not np.isfinite(n)) or pd.isna(n):\n",
    "        return \"\"\n",
    "    n = int(n)\n",
    "    sign = \"-\" if n < 0 else \"\"\n",
    "    s = str(abs(n))\n",
    "    groups = []\n",
    "    while s:\n",
    "        groups.append(s[-3:])\n",
    "        s = s[:-3]\n",
    "    return sign + \" \".join(reversed(groups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# COMPANY TABLE FUNCTION\n",
    "# =============================================================================\n",
    "\n",
    "def create_company_table(df_input, subgroup_name=\"\"):\n",
    "    \"\"\"\n",
    "    Create detailed company table with ML estimates.\n",
    "    \n",
    "    Args:\n",
    "        df_input: DataFrame with organization data\n",
    "        subgroup_name: Name of the subgroup for display\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with formatted company data\n",
    "    \"\"\"\n",
    "    estimator_cols = [\n",
    "        'filter_broad_yes_strict_no', \n",
    "        'filter_strict_no', \n",
    "        'filter_broad_yes',\n",
    "        'claude_total_accepted', \n",
    "        'gpt5_total_accepted', \n",
    "        'gemini_total_accepted'\n",
    "    ]\n",
    "    \n",
    "    rows = []\n",
    "    for _, row in df_input.iterrows():\n",
    "        # Extract founding year\n",
    "        founded_year = \"\"\n",
    "        if 'Founded Date' in row.index and pd.notna(row['Founded Date']):\n",
    "            try:\n",
    "                dt = pd.to_datetime(row['Founded Date'], errors='coerce')\n",
    "                if pd.notna(dt):\n",
    "                    founded_year = str(dt.year)\n",
    "            except (ValueError, TypeError):\n",
    "                pass\n",
    "        \n",
    "        # Get individual estimator values\n",
    "        estimator_values = []\n",
    "        for col in estimator_cols:\n",
    "            if col in row.index:\n",
    "                val = pd.to_numeric(row[col], errors='coerce')\n",
    "                if pd.notna(val):\n",
    "                    estimator_values.append(str(int(val)))\n",
    "                else:\n",
    "                    estimator_values.append(\"-\")\n",
    "            else:\n",
    "                estimator_values.append(\"-\")\n",
    "        \n",
    "        # Determine if using synthetic estimate\n",
    "        q50_pure = pd.to_numeric(row.get('q50', np.nan), errors='coerce')\n",
    "        use_synthetic = pd.isna(q50_pure)\n",
    "        \n",
    "        # Get ML estimate (q50) and CI bounds\n",
    "        if use_synthetic:\n",
    "            ml_q50 = pd.to_numeric(row.get('adjusted_synthetic_q50', np.nan), errors='coerce')\n",
    "            ml_q10 = pd.to_numeric(row.get('adjusted_synthetic_q10', np.nan), errors='coerce')\n",
    "            ml_q90 = pd.to_numeric(row.get('adjusted_synthetic_q90', np.nan), errors='coerce')\n",
    "        else:\n",
    "            ml_q50 = q50_pure\n",
    "            ml_q10 = pd.to_numeric(row.get('q10', np.nan), errors='coerce')\n",
    "            ml_q90 = pd.to_numeric(row.get('q90', np.nan), errors='coerce')\n",
    "        \n",
    "        # Format ML talent estimate with CI\n",
    "        if pd.notna(ml_q50):\n",
    "            ml_str = f\"{format_int_iso(int(ml_q50))}\"\n",
    "            if pd.notna(ml_q10) and pd.notna(ml_q90):\n",
    "                ml_str += f\" ({format_int_iso(int(ml_q10))} - {format_int_iso(int(ml_q90))})\"\n",
    "            if use_synthetic:\n",
    "                ml_str += \" *\"\n",
    "        else:\n",
    "            ml_str = \"-\"\n",
    "        \n",
    "        # Get headcount and calculate ML share\n",
    "        headcount = pd.to_numeric(row.get('total_headcount', np.nan), errors='coerce')\n",
    "        \n",
    "        if pd.notna(ml_q50) and pd.notna(headcount) and headcount > 0:\n",
    "            ml_pct = 100.0 * ml_q50 / headcount\n",
    "            ml_pct_str = f\"{ml_pct:.2f}%\"\n",
    "            \n",
    "            if pd.notna(ml_q10) and pd.notna(ml_q90):\n",
    "                pct_low = 100.0 * ml_q10 / headcount\n",
    "                pct_high = 100.0 * ml_q90 / headcount\n",
    "                ml_pct_str += f\" ({pct_low:.2f}% - {pct_high:.2f}%)\"\n",
    "        else:\n",
    "            ml_pct_str = \"-\"\n",
    "        \n",
    "        # Determine confidence category\n",
    "        category = assign_confidence_category(ml_q10, ml_q50, ml_q90)\n",
    "        \n",
    "        # Get country - try multiple possible column names\n",
    "        country = row.get('country', row.get('Country', row.get('headquarters_location', '')))\n",
    "        \n",
    "        rows.append({\n",
    "            'Company Name': row.get('organization_name', ''),\n",
    "            'Founded': founded_year,\n",
    "            'Country': country,\n",
    "            'Total Staff (LinkedIn)': format_int_iso(int(headcount)) if pd.notna(headcount) else \"-\",\n",
    "            'Individual Estimates [broad+strict, strict, broad, claude, gpt5, gemini]': f\"[{', '.join(estimator_values)}]\",\n",
    "            'ML Talent q50 (q10 - q90)': ml_str,\n",
    "            'ML % of Total': ml_pct_str,\n",
    "            'Category': category\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "print(\"Company table function loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ML ESTIMATES PLOT FUNCTION\n",
    "# =============================================================================\n",
    "\n",
    "def create_ml_estimates_plot_all_orgs(df_plot, figsize=(16, 8), title_suffix=\"\"):\n",
    "    \"\"\"\n",
    "    Create visualization of ML estimates, filtering to confident organizations.\n",
    "    \n",
    "    Args:\n",
    "        df_plot: DataFrame with organization data (will be filtered to q10 > 0)\n",
    "        figsize: Figure size tuple\n",
    "        title_suffix: Optional suffix for plot title\n",
    "    \n",
    "    Returns:\n",
    "        fig, ax, df_sorted (filtered to q10 > 0 only)\n",
    "    \"\"\"\n",
    "    filter_cols = ['filter_broad_yes', 'filter_strict_no', 'filter_broad_yes_strict_no']\n",
    "    llm_cols = ['gemini_total_accepted', 'claude_total_accepted', 'gpt5_total_accepted']\n",
    "    \n",
    "    df_sorted = df_plot.copy()\n",
    "    \n",
    "    # Determine which CI to use for each org\n",
    "    df_sorted['_use_pure_probit'] = pd.to_numeric(df_sorted['q50'], errors='coerce').notna()\n",
    "    \n",
    "    df_sorted['_central'] = np.where(\n",
    "        df_sorted['_use_pure_probit'],\n",
    "        pd.to_numeric(df_sorted['q50'], errors='coerce'),\n",
    "        pd.to_numeric(df_sorted['adjusted_synthetic_q50'], errors='coerce')\n",
    "    )\n",
    "    df_sorted['_lower'] = np.where(\n",
    "        df_sorted['_use_pure_probit'],\n",
    "        pd.to_numeric(df_sorted['q10'], errors='coerce'),\n",
    "        pd.to_numeric(df_sorted['adjusted_synthetic_q10'], errors='coerce')\n",
    "    )\n",
    "    df_sorted['_upper'] = np.where(\n",
    "        df_sorted['_use_pure_probit'],\n",
    "        pd.to_numeric(df_sorted['q90'], errors='coerce'),\n",
    "        pd.to_numeric(df_sorted['adjusted_synthetic_q90'], errors='coerce')\n",
    "    )\n",
    "    \n",
    "    # Filter to companies where q10 > 0 (CI excludes zero)\n",
    "    mask_ci_excludes_zero = df_sorted['_lower'] > 0\n",
    "    df_sorted = df_sorted[mask_ci_excludes_zero].copy()\n",
    "    \n",
    "    # Sort by central estimate\n",
    "    df_sorted['_sort_key'] = df_sorted['_central'].fillna(0)\n",
    "    df_sorted = df_sorted.sort_values('_sort_key').reset_index(drop=True)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    x = np.arange(len(df_sorted))\n",
    "    \n",
    "    offset_step = 0.10\n",
    "    \n",
    "    # Layer 1: Keyword filter estimates\n",
    "    filter_handles = []\n",
    "    for i, col in enumerate(filter_cols):\n",
    "        if col not in df_sorted.columns:\n",
    "            continue\n",
    "        y = pd.to_numeric(df_sorted[col], errors='coerce').values\n",
    "        mask = np.isfinite(y) & (y > 0)\n",
    "        x_pos = x + (i - 1) * offset_step\n",
    "        \n",
    "        style = ESTIMATOR_STYLES.get(col, {'color': PALETTE['gray'], 'marker': 'o', 'size': 24})\n",
    "        sc = ax.scatter(\n",
    "            x_pos[mask], y[mask],\n",
    "            s=style['size'], marker=style['marker'],\n",
    "            c=style['color'], alpha=0.35,\n",
    "            linewidths=0, zorder=1,\n",
    "            label=ESTIMATOR_LABELS.get(col, col)\n",
    "        )\n",
    "        filter_handles.append((sc, ESTIMATOR_LABELS.get(col, col)))\n",
    "    \n",
    "    # Layer 2: LLM estimates\n",
    "    llm_handles = []\n",
    "    for j, col in enumerate(llm_cols):\n",
    "        if col not in df_sorted.columns:\n",
    "            continue\n",
    "        y = pd.to_numeric(df_sorted[col], errors='coerce').values\n",
    "        mask = np.isfinite(y) & (y > 0)\n",
    "        x_pos = x + (j - 1) * offset_step\n",
    "        \n",
    "        style = ESTIMATOR_STYLES.get(col, {'color': PALETTE['blue'], 'marker': 'D', 'size': 36})\n",
    "        sc = ax.scatter(\n",
    "            x_pos[mask], y[mask],\n",
    "            s=style['size'], marker=style['marker'],\n",
    "            c=style['color'], alpha=0.85,\n",
    "            edgecolors='white', linewidths=0.5, zorder=2,\n",
    "            label=ESTIMATOR_LABELS.get(col, col)\n",
    "        )\n",
    "        llm_handles.append((sc, ESTIMATOR_LABELS.get(col, col)))\n",
    "    \n",
    "    # Layer 3: Confidence intervals\n",
    "    central = df_sorted['_central'].values\n",
    "    lower = df_sorted['_lower'].values\n",
    "    upper = df_sorted['_upper'].values\n",
    "    use_pure = df_sorted['_use_pure_probit'].values\n",
    "    \n",
    "    eps = 0.5\n",
    "    lower = np.maximum(lower, eps)\n",
    "    central = np.maximum(central, eps)\n",
    "    \n",
    "    yerr_lower = np.clip(central - lower, 0, None)\n",
    "    yerr_upper = np.clip(upper - central, 0, None)\n",
    "    \n",
    "    mask_valid = np.isfinite(central) & (central > 0)\n",
    "    \n",
    "    ci_handles = []\n",
    "    \n",
    "    # Pure Probit CI\n",
    "    mask_pure = mask_valid & use_pure\n",
    "    if np.any(mask_pure):\n",
    "        err_pure = ax.errorbar(\n",
    "            x[mask_pure], central[mask_pure],\n",
    "            yerr=np.vstack([yerr_lower[mask_pure], yerr_upper[mask_pure]]),\n",
    "            fmt='o', \n",
    "            mfc='white', mec=COLORS['ci_pure_probit'], mew=1.8, ms=5,\n",
    "            ecolor=COLORS['ci_pure_probit'], elinewidth=1.2, capsize=2.5, capthick=1.2,\n",
    "            zorder=4\n",
    "        )\n",
    "        ci_handles.append((err_pure, 'Pure Probit 80% CI'))\n",
    "    \n",
    "    # Adjusted Synthetic CI\n",
    "    mask_synthetic = mask_valid & (~use_pure)\n",
    "    if np.any(mask_synthetic):\n",
    "        err_synth = ax.errorbar(\n",
    "            x[mask_synthetic], central[mask_synthetic],\n",
    "            yerr=np.vstack([yerr_lower[mask_synthetic], yerr_upper[mask_synthetic]]),\n",
    "            fmt='o', \n",
    "            mfc='white', mec=COLORS['ci_adjusted_synthetic'], mew=1.8, ms=5,\n",
    "            ecolor=COLORS['ci_adjusted_synthetic'], elinewidth=1.2, capsize=2.5, capthick=1.2,\n",
    "            zorder=4\n",
    "        )\n",
    "        ci_handles.append((err_synth, 'Adjusted Synthetic 80% CI'))\n",
    "    \n",
    "    # Axis formatting\n",
    "    format_log_axis(ax, axis='y', limits=(1, 10000))\n",
    "    \n",
    "    ax.set_xlabel('Organizations (sorted by ML estimate)', fontsize=FONT_SIZES['axis_label'])\n",
    "    ax.set_ylabel('Estimated ML Talent', fontsize=FONT_SIZES['axis_label'])\n",
    "    ax.set_title(f'ML Talent Estimates by Organization{title_suffix}', fontsize=FONT_SIZES['title'], fontweight='medium', pad=10)\n",
    "    \n",
    "    # X-axis labels\n",
    "    org_col = 'organization_name' if 'organization_name' in df_sorted.columns else None\n",
    "    if org_col:\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels(\n",
    "            df_sorted[org_col].astype(str).tolist(), \n",
    "            rotation=45, ha='right', \n",
    "            fontsize=FONT_SIZES['org_label']\n",
    "        )\n",
    "    \n",
    "    # Legend\n",
    "    ci_items = []\n",
    "    for handle, label in ci_handles:\n",
    "        color = COLORS['ci_pure_probit'] if 'Pure' in label else COLORS['ci_adjusted_synthetic']\n",
    "        ci_items.append(Line2D(\n",
    "            [0], [0], marker='o', color=color,\n",
    "            markerfacecolor='white', markeredgecolor=color,\n",
    "            markeredgewidth=1.8, markersize=6,\n",
    "            linestyle='-', linewidth=1.2,\n",
    "            label=f'  {label}'\n",
    "        ))\n",
    "    \n",
    "    llm_items = []\n",
    "    for handle, label in llm_handles:\n",
    "        style = [s for c, s in ESTIMATOR_STYLES.items() if ESTIMATOR_LABELS.get(c) == label]\n",
    "        if style:\n",
    "            s = style[0]\n",
    "            llm_items.append(Line2D(\n",
    "                [0], [0], marker=s['marker'], color='w',\n",
    "                markerfacecolor=s['color'], markeredgecolor='white',\n",
    "                markersize=7, linestyle='None',\n",
    "                label=f'  {label}'\n",
    "            ))\n",
    "    \n",
    "    keyword_items = []\n",
    "    for handle, label in filter_handles:\n",
    "        style = [s for c, s in ESTIMATOR_STYLES.items() if ESTIMATOR_LABELS.get(c) == label]\n",
    "        if style:\n",
    "            s = style[0]\n",
    "            keyword_items.append(Line2D(\n",
    "                [0], [0], marker=s['marker'], color='w',\n",
    "                markerfacecolor=s['color'], markeredgecolor='none',\n",
    "                markersize=5, linestyle='None', alpha=0.5,\n",
    "                label=f'  {label}'\n",
    "            ))\n",
    "    \n",
    "    ci_header = Line2D([0], [0], color='none', label='Confidence Intervals:')\n",
    "    llm_header = Line2D([0], [0], color='none', label='LLM Estimates:')\n",
    "    keyword_header = Line2D([0], [0], color='none', label='Keyword Filters:')\n",
    "    spacer = Line2D([0], [0], color='none', linestyle='None', label=' ')\n",
    "    \n",
    "    max_len = max(len(ci_items), len(llm_items), len(keyword_items))\n",
    "    while len(ci_items) < max_len:\n",
    "        ci_items.append(spacer)\n",
    "    while len(llm_items) < max_len:\n",
    "        llm_items.append(spacer)\n",
    "    while len(keyword_items) < max_len:\n",
    "        keyword_items.append(spacer)\n",
    "    \n",
    "    legend_elements = []\n",
    "    legend_elements.append(ci_header)\n",
    "    legend_elements.extend(ci_items)\n",
    "    legend_elements.append(llm_header)\n",
    "    legend_elements.extend(llm_items)\n",
    "    legend_elements.append(keyword_header)\n",
    "    legend_elements.extend(keyword_items)\n",
    "    \n",
    "    ax.legend(\n",
    "        handles=legend_elements,\n",
    "        loc='upper center',\n",
    "        bbox_to_anchor=(0.5, -0.35),\n",
    "        ncol=3,\n",
    "        fontsize=FONT_SIZES['legend'],\n",
    "        frameon=False,\n",
    "        columnspacing=2.5,\n",
    "        handletextpad=0.5,\n",
    "    )\n",
    "    \n",
    "    ax.grid(True, which='major', alpha=0.20, linewidth=0.4, color=COLORS['gridline'])\n",
    "    ax.set_axisbelow(True)\n",
    "    \n",
    "    plt.subplots_adjust(left=0.05, right=0.95, top=0.92, bottom=0.35)\n",
    "    \n",
    "    return fig, ax, df_sorted\n",
    "\n",
    "print(\"ML estimates plot function loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# LANDSCAPE PLOT FUNCTION\n# =============================================================================\n\ntry:\n    from adjustText import adjust_text\n    HAS_ADJUSTTEXT = True\nexcept ImportError:\n    HAS_ADJUSTTEXT = False\n    print(\"Note: Install adjustText for better label placement: pip install adjustText\")\n\n\ndef create_landscape_plot(df_input, title_suffix=\"\", x_max=100, figsize=(11, 7), max_labels=25, log_x=True, label_all=False):\n    \"\"\"\n    Create ML talent landscape scatter plot.\n    \n    Args:\n        df_input: DataFrame with organization data\n        title_suffix: Optional suffix for plot title\n        x_max: Maximum x-axis value (ML share %)\n        log_x: Use logarithmic x-axis (default True)\n        figsize: Figure size tuple\n        max_labels: Maximum number of organization labels to show\n        label_all: If True, label all organizations (not just Probable)\n    \n    Returns:\n        fig, ax, plot_df\n    \"\"\"\n    # Prepare data - use pure probit if available, else adjusted synthetic\n    q10_pure = pd.to_numeric(df_input['q10'], errors='coerce') if 'q10' in df_input.columns else pd.Series(np.nan, index=df_input.index)\n    q50_pure = pd.to_numeric(df_input['q50'], errors='coerce') if 'q50' in df_input.columns else pd.Series(np.nan, index=df_input.index)\n    q90_pure = pd.to_numeric(df_input['q90'], errors='coerce') if 'q90' in df_input.columns else pd.Series(np.nan, index=df_input.index)\n    q10_synthetic = pd.to_numeric(df_input['adjusted_synthetic_q10'], errors='coerce')\n    q50_synthetic = pd.to_numeric(df_input['adjusted_synthetic_q50'], errors='coerce')\n    q90_synthetic = pd.to_numeric(df_input['adjusted_synthetic_q90'], errors='coerce')\n    \n    ml_q10 = q10_pure.where(q50_pure.notna(), q10_synthetic)\n    ml_q50 = q50_pure.where(q50_pure.notna(), q50_synthetic)\n    ml_q90 = q90_pure.where(q50_pure.notna(), q90_synthetic)\n    \n    plot_df = pd.DataFrame({\n        'org': df_input['organization_name'].astype(str),\n        'ml_n': ml_q50,\n        'ml_q10': ml_q10,\n        'ml_q90': ml_q90,\n        'emp': pd.to_numeric(df_input['total_headcount'], errors='coerce'),\n        'used_pure_probit': q50_pure.notna()\n    })\n    \n    plot_df['ml_pct'] = (plot_df['ml_n'] / plot_df['emp']) * 100.0\n    plot_df['ml_pct'] = plot_df['ml_pct'].clip(lower=0, upper=100)\n    \n    plot_df = plot_df.replace([np.inf, -np.inf], np.nan).dropna(subset=['ml_n', 'emp', 'ml_pct'])\n    plot_df = plot_df[(plot_df['ml_n'] >= 0) & (plot_df['emp'] > 0)]\n    \n    plot_df['cluster'] = [assign_confidence_category(q10, q50, q90) \n                          for q10, q50, q90 in plot_df[['ml_q10', 'ml_n', 'ml_q90']].values]\n    \n    fig, ax = plt.subplots(figsize=figsize)\n    \n    marker_sizes = {\n        'Probable': 80,\n        'Possible': 64,\n        'Non-zero': 48,\n        'Not Detected': 36,\n    }\n    \n    for cluster_name in ['Not Detected', 'Non-zero', 'Possible', 'Probable']:\n        sub_df = plot_df[plot_df['cluster'] == cluster_name]\n        if len(sub_df) == 0:\n            continue\n        \n        is_highlight = cluster_name in ['Probable', 'Possible']\n        \n        ax.scatter(\n            sub_df['ml_pct'], sub_df['ml_n'],\n            s=marker_sizes[cluster_name],\n            c=LANDSCAPE_PALETTE[cluster_name],\n            marker=LANDSCAPE_MARKERS[cluster_name],\n            alpha=0.85 if is_highlight else 0.45,\n            edgecolors='white' if is_highlight else 'none',\n            linewidths=0.6 if is_highlight else 0,\n            label=cluster_name,\n            zorder=3 if is_highlight else 2\n        )\n    \n    # Labels for organizations\n    if label_all:\n        labeled_df = plot_df.copy()\n    else:\n        labeled_df = plot_df[plot_df['cluster'] == 'Probable'].copy()\n    labeled_df = labeled_df.sort_values('ml_n', ascending=False).head(max_labels)\n    \n    if len(labeled_df) > 0:\n        # Simple approach: place labels directly next to points with small offset\n        texts = []\n        for _, data_row in labeled_df.iterrows():\n            point_x = data_row['ml_pct']\n            point_y = data_row['ml_n']\n            org_name = data_row['org']\n            \n            # Add text annotation\n            txt = ax.annotate(\n                org_name,\n                xy=(point_x, point_y),\n                xytext=(5, 5),  # Small offset in points\n                textcoords='offset points',\n                fontsize=FONT_SIZES['org_label'],\n                ha='left', va='bottom',\n                color='#404040',\n                arrowprops=dict(\n                    arrowstyle='-',\n                    lw=0.4,\n                    color='#909090',\n                    alpha=0.5,\n                ),\n            )\n            texts.append(txt)\n        \n        # Use adjustText if available to avoid overlaps\n        if HAS_ADJUSTTEXT and len(texts) > 1:\n            adjust_text(texts, ax=ax, \n                       arrowprops=dict(arrowstyle='-', color='#909090', alpha=0.5, lw=0.4),\n                       expand_points=(1.5, 1.5),\n                       force_points=(0.5, 0.5))\n    \n    # Axis formatting\n    if log_x:\n        ax.set_xscale('log')\n        ax.set_xlim(0.001, x_max)\n        ax.set_xticks([0.001, 0.01, 0.1, 1, 10, 100])\n        ax.set_xticklabels(['0.001%', '0.01%', '0.1%', '1%', '10%', '100%'])\n    else:\n        ax.set_xlim(0, x_max)\n    format_log_axis(ax, axis='y', limits=(1, 50000))\n    \n    ax.set_xlabel('ML Share (%)', fontsize=FONT_SIZES['axis_label'])\n    ax.set_ylabel('ML Staff Count (q50)', fontsize=FONT_SIZES['axis_label'])\n    ax.set_title(f'ML Talent Landscape{title_suffix}', fontsize=FONT_SIZES['title'], fontweight='medium', pad=10)\n    \n    # Legend\n    cluster_counts = plot_df['cluster'].value_counts()\n    \n    legend_handles = []\n    for cluster in ['Probable', 'Possible', 'Non-zero', 'Not Detected']:\n        count = cluster_counts.get(cluster, 0)\n        is_highlight = cluster in ['Probable', 'Possible']\n        legend_handles.append(\n            plt.scatter([], [], \n                s=marker_sizes[cluster] * 0.8,\n                c=LANDSCAPE_PALETTE[cluster],\n                marker=LANDSCAPE_MARKERS[cluster],\n                alpha=0.85 if is_highlight else 0.45,\n                edgecolors='white' if is_highlight else 'none',\n                linewidths=0.6 if is_highlight else 0,\n                label=f'{cluster} (n={count})'\n            )\n        )\n    \n    ax.legend(\n        handles=legend_handles,\n        loc='center left',\n        bbox_to_anchor=(1.02, 0.5),\n        frameon=True,\n        framealpha=0.95,\n        edgecolor='#E0E0E0',\n        fontsize=FONT_SIZES['legend'],\n    )\n    \n    ax.grid(True, which='major', alpha=0.20, linewidth=0.4, color=COLORS['gridline'])\n    ax.set_axisbelow(True)\n    \n    plt.subplots_adjust(left=0.08, right=0.78, top=0.92, bottom=0.08)\n    \n    n_pure = plot_df['used_pure_probit'].sum()\n    n_synthetic = len(plot_df) - n_pure\n    print(f\"Estimate source: {n_pure} pure probit, {n_synthetic} adjusted synthetic\")\n    \n    return fig, ax, plot_df\n\nprint(\"Landscape plot function loaded\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 1: Load Comparator Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load comparator datasets\n",
    "df_ml = pd.read_csv(DATA_DIR / 'final_results_comparator_ml.csv')\n",
    "df_non_ml = pd.read_csv(DATA_DIR / 'final_results_comparator_non_ml.csv')\n",
    "\n",
    "print(f\"ML Comparators: {len(df_ml)} organizations\")\n",
    "print(f\"Non-ML Comparators: {len(df_non_ml)} organizations\")\n",
    "\n",
    "print(f\"\\nML Comparator organizations:\")\n",
    "print(df_ml['organization_name'].tolist())\n",
    "\n",
    "print(f\"\\nNon-ML Comparator organizations:\")\n",
    "print(df_non_ml['organization_name'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 2: ML Comparators Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create company table for ML comparators\n",
    "company_table_ml = create_company_table(df_ml, subgroup_name=\"ML Comparators\")\n",
    "\n",
    "# Sort by ML talent estimate\n",
    "def extract_ml_for_sort(ml_str):\n",
    "    \"\"\"Extract numeric ML value for sorting.\"\"\"\n",
    "    if ml_str == \"-\":\n",
    "        return 0\n",
    "    match = re.match(r'([\\d\\s]+)', ml_str.replace(' ', ''))\n",
    "    if match:\n",
    "        return int(match.group(1).replace(' ', ''))\n",
    "    return 0\n",
    "\n",
    "company_table_ml['_sort_key'] = company_table_ml['ML Talent q50 (q10 - q90)'].apply(extract_ml_for_sort)\n",
    "company_table_ml = company_table_ml.sort_values('_sort_key', ascending=False).drop(columns=['_sort_key'])\n",
    "\n",
    "# Save to output\n",
    "if SAVE_OUTPUTS:\n",
    "    output_path = DATA_DIR / 'output' / 'company_table_comparator_ml.csv'\n",
    "    company_table_ml.to_csv(output_path, index=False)\n",
    "    print(f\"Saved company table to {output_path}\")\n",
    "\n",
    "display(company_table_ml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ML estimates plot for ML comparators\n",
    "fig_ml, ax_ml, df_ml_sorted = create_ml_estimates_plot_all_orgs(\n",
    "    df_ml, \n",
    "    figsize=(14, 7),\n",
    "    title_suffix=\" - ML Comparators (Established ML Orgs)\"\n",
    ")\n",
    "\n",
    "# Print summary\n",
    "n_total = len(df_ml)\n",
    "n_plotted = len(df_ml_sorted)\n",
    "n_excluded = n_total - n_plotted\n",
    "n_pure = df_ml_sorted['_use_pure_probit'].sum() if len(df_ml_sorted) > 0 else 0\n",
    "n_synthetic = n_plotted - n_pure\n",
    "\n",
    "print(f\"Plot Summary (ML Comparators):\")\n",
    "print(f\"  Total organizations: {n_total}\")\n",
    "print(f\"  Plotted (q10 > 0): {n_plotted}\")\n",
    "print(f\"  Excluded (q10 = 0): {n_excluded}\")\n",
    "print(f\"  Using Pure Probit CI: {n_pure}\")\n",
    "print(f\"  Using Adjusted Synthetic CI: {n_synthetic}\")\n",
    "\n",
    "if SAVE_OUTPUTS:\n",
    "    fig_ml.savefig(DATA_DIR / 'output' / 'ml_estimates_comparator_ml.png', dpi=200, bbox_inches='tight')\n",
    "    print(f\"\\nSaved: {DATA_DIR / 'output' / 'ml_estimates_comparator_ml.png'}\")\n",
    "\n",
    "plt.show()\n",
    "plt.close(fig_ml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Create landscape plot for ML comparators\nfig_landscape_ml, ax_landscape_ml, plot_ml = create_landscape_plot(\n    df_ml, \n    title_suffix=\" - ML Comparators\",\n    figsize=(12, 8),\n    max_labels=50,\n    label_all=True\n)\n\nprint(f\"\\nCluster distribution (ML Comparators, N={len(plot_ml)}):\")\nfor cluster in ['Probable', 'Possible', 'Non-zero', 'Not Detected']:\n    count = (plot_ml['cluster'] == cluster).sum()\n    print(f\"  {cluster}: {count}\")\n\nif SAVE_OUTPUTS:\n    fig_landscape_ml.savefig(DATA_DIR / 'output' / 'ml_landscape_comparator_ml.png', dpi=200, bbox_inches='tight')\n    print(f\"\\nSaved: {DATA_DIR / 'output' / 'ml_landscape_comparator_ml.png'}\")\n\nplt.show()\nplt.close(fig_landscape_ml)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 3: Non-ML Comparators Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create company table for Non-ML comparators\n",
    "company_table_non_ml = create_company_table(df_non_ml, subgroup_name=\"Non-ML Comparators\")\n",
    "\n",
    "# Sort by ML talent estimate\n",
    "company_table_non_ml['_sort_key'] = company_table_non_ml['ML Talent q50 (q10 - q90)'].apply(extract_ml_for_sort)\n",
    "company_table_non_ml = company_table_non_ml.sort_values('_sort_key', ascending=False).drop(columns=['_sort_key'])\n",
    "\n",
    "# Save to output\n",
    "if SAVE_OUTPUTS:\n",
    "    output_path = DATA_DIR / 'output' / 'company_table_comparator_non_ml.csv'\n",
    "    company_table_non_ml.to_csv(output_path, index=False)\n",
    "    print(f\"Saved company table to {output_path}\")\n",
    "\n",
    "display(company_table_non_ml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ML estimates plot for Non-ML comparators\n",
    "fig_non_ml, ax_non_ml, df_non_ml_sorted = create_ml_estimates_plot_all_orgs(\n",
    "    df_non_ml, \n",
    "    figsize=(14, 7),\n",
    "    title_suffix=\" - Non-ML Comparators (Negative Controls)\"\n",
    ")\n",
    "\n",
    "# Print summary\n",
    "n_total = len(df_non_ml)\n",
    "n_plotted = len(df_non_ml_sorted)\n",
    "n_excluded = n_total - n_plotted\n",
    "n_pure = df_non_ml_sorted['_use_pure_probit'].sum() if len(df_non_ml_sorted) > 0 else 0\n",
    "n_synthetic = n_plotted - n_pure\n",
    "\n",
    "print(f\"Plot Summary (Non-ML Comparators):\")\n",
    "print(f\"  Total organizations: {n_total}\")\n",
    "print(f\"  Plotted (q10 > 0): {n_plotted}\")\n",
    "print(f\"  Excluded (q10 = 0): {n_excluded}\")\n",
    "print(f\"  Using Pure Probit CI: {n_pure}\")\n",
    "print(f\"  Using Adjusted Synthetic CI: {n_synthetic}\")\n",
    "\n",
    "if SAVE_OUTPUTS:\n",
    "    fig_non_ml.savefig(DATA_DIR / 'output' / 'ml_estimates_comparator_non_ml.png', dpi=200, bbox_inches='tight')\n",
    "    print(f\"\\nSaved: {DATA_DIR / 'output' / 'ml_estimates_comparator_non_ml.png'}\")\n",
    "\n",
    "plt.show()\n",
    "plt.close(fig_non_ml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Create landscape plot for Non-ML comparators\nfig_landscape_non_ml, ax_landscape_non_ml, plot_non_ml = create_landscape_plot(\n    df_non_ml, \n    title_suffix=\" - Non-ML Comparators\",\n    figsize=(12, 8),\n    max_labels=50,\n    label_all=True\n)\n\nprint(f\"\\nCluster distribution (Non-ML Comparators, N={len(plot_non_ml)}):\")\nfor cluster in ['Probable', 'Possible', 'Non-zero', 'Not Detected']:\n    count = (plot_non_ml['cluster'] == cluster).sum()\n    print(f\"  {cluster}: {count}\")\n\nif SAVE_OUTPUTS:\n    fig_landscape_non_ml.savefig(DATA_DIR / 'output' / 'ml_landscape_comparator_non_ml.png', dpi=200, bbox_inches='tight')\n    print(f\"\\nSaved: {DATA_DIR / 'output' / 'ml_landscape_comparator_non_ml.png'}\")\n\nplt.show()\nplt.close(fig_landscape_non_ml)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "Generated outputs:\n",
    "\n",
    "**ML Comparators (Established ML Orgs):**\n",
    "- `output/company_table_comparator_ml.csv`\n",
    "- `output/ml_estimates_comparator_ml.png`\n",
    "- `output/ml_landscape_comparator_ml.png`\n",
    "\n",
    "**Non-ML Comparators (Negative Controls):**\n",
    "- `output/company_table_comparator_non_ml.csv`\n",
    "- `output/ml_estimates_comparator_non_ml.png`\n",
    "- `output/ml_landscape_comparator_non_ml.png`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of all outputs\n",
    "print(\"=\" * 60)\n",
    "print(\"COMPARATOR ANALYSIS COMPLETE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nML Comparators ({len(df_ml)} organizations):\")\n",
    "print(f\"  - Company Table: {len(company_table_ml)} rows\")\n",
    "print(f\"  - ML Estimates Plot: {len(df_ml_sorted)} organizations with q10 > 0\")\n",
    "print(f\"  - Landscape Plot: {len(plot_ml)} valid data points\")\n",
    "\n",
    "print(f\"\\nNon-ML Comparators ({len(df_non_ml)} organizations):\")\n",
    "print(f\"  - Company Table: {len(company_table_non_ml)} rows\")\n",
    "print(f\"  - ML Estimates Plot: {len(df_non_ml_sorted)} organizations with q10 > 0\")\n",
    "print(f\"  - Landscape Plot: {len(plot_non_ml)} valid data points\")\n",
    "\n",
    "if SAVE_OUTPUTS:\n",
    "    print(f\"\\nAll outputs saved to: {(DATA_DIR / 'output').resolve()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}